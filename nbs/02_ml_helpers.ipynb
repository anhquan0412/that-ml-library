{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ml_helpers\n",
    "\n",
    "\n",
    "> This module contains several Python functions for running a quick ML prototype on your processed dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp ml_helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "from that_ml_library.utils import *\n",
    "from that_ml_library.chart_plotting import plot_permutation_importances,plot_confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_validate, train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\n",
    "from sklearn.metrics import f1_score,accuracy_score,classification_report,log_loss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def run_logistic_regression(X_trn:pd.DataFrame|np.ndarray, # Training features\n",
    "                            y_trn:pd.Series|np.ndarray, # Training label\n",
    "                            multi_class='multinomial', # sklearn's log reg multiclass option\n",
    "                            solver='newton-cg', # sklearn's log reg solver option\n",
    "                            penalty=None, # sklearn's log reg penalty option\n",
    "                            max_iter=10000 # sklearn's log reg max iteration option\n",
    "                           ):\n",
    "    \"Perform Sklearn logistic regression, then print coefficients and classification report\"\n",
    "    model = LogisticRegression(random_state=0, multi_class=multi_class, \n",
    "                               penalty=penalty, solver=solver,max_iter=max_iter).fit(X_trn, y_trn)\n",
    "    preds = model.predict(X_trn)\n",
    "    prob_preds = model.predict_proba(X_trn)\n",
    "    print('-'*100)\n",
    "    print('Intercept: \\n', model.intercept_)\n",
    "    print('Coefficients: \\n', model.coef_)\n",
    "    print('Coefficients exp :\\n',np.exp(model.coef_))\n",
    "\n",
    "    print('-'*100)\n",
    "    print('Log loss: ',log_loss(y_trn,prob_preds))\n",
    "    print('-'*100)\n",
    "    print(classification_report(y_trn,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/anhquan0412/that-ml-library/blob/main/that_ml_library/ml_helpers.py#L22){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### run_logistic_regression\n",
       "\n",
       ">      run_logistic_regression (X_trn:pandas.core.frame.DataFrame|numpy.ndarray,\n",
       ">                               y_trn:pandas.core.series.Series|numpy.ndarray,\n",
       ">                               multi_class='multinomial', solver='newton-cg',\n",
       ">                               penalty=None, max_iter=10000)\n",
       "\n",
       "Perform Sklearn logistic regression, then print coefficients and classification report\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| X_trn | pd.DataFrame \\| np.ndarray |  | Training features |\n",
       "| y_trn | pd.Series \\| np.ndarray |  | Training label |\n",
       "| multi_class | str | multinomial | sklearn's log reg multiclass option |\n",
       "| solver | str | newton-cg | sklearn's log reg solver option |\n",
       "| penalty | NoneType | None | sklearn's log reg penalty option |\n",
       "| max_iter | int | 10000 | sklearn's log reg max iteration option |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/anhquan0412/that-ml-library/blob/main/that_ml_library/ml_helpers.py#L22){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### run_logistic_regression\n",
       "\n",
       ">      run_logistic_regression (X_trn:pandas.core.frame.DataFrame|numpy.ndarray,\n",
       ">                               y_trn:pandas.core.series.Series|numpy.ndarray,\n",
       ">                               multi_class='multinomial', solver='newton-cg',\n",
       ">                               penalty=None, max_iter=10000)\n",
       "\n",
       "Perform Sklearn logistic regression, then print coefficients and classification report\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| X_trn | pd.DataFrame \\| np.ndarray |  | Training features |\n",
       "| y_trn | pd.Series \\| np.ndarray |  | Training label |\n",
       "| multi_class | str | multinomial | sklearn's log reg multiclass option |\n",
       "| solver | str | newton-cg | sklearn's log reg solver option |\n",
       "| penalty | NoneType | None | sklearn's log reg penalty option |\n",
       "| max_iter | int | 10000 | sklearn's log reg max iteration option |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(run_logistic_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def run_multinomial_statmodel(X_trn:pd.DataFrame|np.ndarray, # Training features\n",
    "                              y_trn:pd.Series|np.ndarray, # Training label\n",
    "                              add_constant=False # To add a constant column to X_trn\n",
    "                             ):\n",
    "    \"Perform multinominal logit from statsmodel, then print results and classification report\"\n",
    "    if add_constant:\n",
    "        X_trn = sm.add_constant(X_trn)\n",
    "    logit_model=sm.MNLogit(y_trn,X_trn)\n",
    "    result=logit_model.fit()\n",
    "    stats1=result.summary()\n",
    "    print(stats1)\n",
    "    prob_preds = logit_model.predict(params = result.params.values)\n",
    "    print('-'*100)\n",
    "    print('Log loss: ',log_loss(y_trn,prob_preds))\n",
    "    print('-'*100)\n",
    "    print(classification_report(y_trn,np.argmax(prob_preds,axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/anhquan0412/that-ml-library/blob/main/that_ml_library/ml_helpers.py#L45){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### run_multinomial_statmodel\n",
       "\n",
       ">      run_multinomial_statmodel\n",
       ">                                 (X_trn:pandas.core.frame.DataFrame|numpy.ndarr\n",
       ">                                 ay,\n",
       ">                                 y_trn:pandas.core.series.Series|numpy.ndarray,\n",
       ">                                 add_constant=False)\n",
       "\n",
       "Perform multinominal logit from statsmodel, then print results and classification report\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| X_trn | pd.DataFrame \\| np.ndarray |  | Training features |\n",
       "| y_trn | pd.Series \\| np.ndarray |  | Training label |\n",
       "| add_constant | bool | False | To add a constant column to X_trn |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/anhquan0412/that-ml-library/blob/main/that_ml_library/ml_helpers.py#L45){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### run_multinomial_statmodel\n",
       "\n",
       ">      run_multinomial_statmodel\n",
       ">                                 (X_trn:pandas.core.frame.DataFrame|numpy.ndarr\n",
       ">                                 ay,\n",
       ">                                 y_trn:pandas.core.series.Series|numpy.ndarray,\n",
       ">                                 add_constant=False)\n",
       "\n",
       "Perform multinominal logit from statsmodel, then print results and classification report\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| X_trn | pd.DataFrame \\| np.ndarray |  | Training features |\n",
       "| y_trn | pd.Series \\| np.ndarray |  | Training label |\n",
       "| add_constant | bool | False | To add a constant column to X_trn |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(run_multinomial_statmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def run_sklearn_classification_model(model_name:str, # sklearn's Machine Learning model to try. Currently support DecisionTree,AdaBoost,RandomForest\n",
    "                                     model_params:dict, # A dictionary containing model's hyperparameters\n",
    "                                     X_trn:pd.DataFrame|np.ndarray, # Training features\n",
    "                                    y_trn:pd.Series|np.ndarray, # Training label\n",
    "                                     class_names:list, # List of names associated with the labels (same order); e.g. ['no','yes']\n",
    "                                     val_ratio=0.2, # Validation set ratio for train_test_split\n",
    "                                     seed=42, # Random seed\n",
    "                                     plot_fea_imp=True # To plot feature importances (permutation technique)\n",
    "                                    ):\n",
    "    np.random.seed(seed)\n",
    "    if val_ratio is not None:\n",
    "        X_trn,X_test,y_trn,y_test = train_test_split(X_trn,y_trn,test_size=val_ratio,random_state=seed)\n",
    "    \n",
    "\n",
    "    if model_name=='DecisionTree':\n",
    "        _model = DecisionTreeClassifier(random_state=seed,**model_params)\n",
    "    elif model_name=='AdaBoost':\n",
    "        dt_params={k.split('__')[1]:v for k,v in model_params.items() if 'base_estimator' in k}\n",
    "        abc_params={k:v for k,v in model_params.items() if 'base_estimator' not in k}        \n",
    "        print(f'Decision Tree params: {dt_params}')\n",
    "        print(f'AdaBoost params: {abc_params}')\n",
    "        dt = DecisionTreeClassifier(random_state=seed,**dt_params)\n",
    "        _model = AdaBoostClassifier(base_estimator=dt,random_state=seed,algorithm='SAMME',**abc_params)\n",
    "    elif model_name=='RandomForest':\n",
    "        _model = RandomForestClassifier(random_state=seed,**model_params)\n",
    "    else:\n",
    "        print('Unsupported model')\n",
    "        return\n",
    "\n",
    "    _model = _model.fit(X_trn,y_trn)\n",
    "    \n",
    "    pred_trn = _model.predict(X_trn)\n",
    "    prob_trn = _model.predict_proba(X_trn)\n",
    "\n",
    "    print('-'*30 + ' Train set ' + '-'*30)\n",
    "    print(f'Log loss: {log_loss(y_trn,prob_trn)}')\n",
    "    print(classification_report(y_trn, pred_trn, target_names=class_names))\n",
    "    \n",
    "    if val_ratio is not None:\n",
    "        pred_val = _model.predict(X_test)\n",
    "        prob_val = _model.predict_proba(X_test)\n",
    "        print('-'*30 + ' Test set ' + '-'*30)\n",
    "        print(f'Log loss: {log_loss(y_test,prob_val)}')\n",
    "        print(classification_report(y_test, pred_val, target_names=class_names))\n",
    "\n",
    "        print('-'*100)\n",
    "        df2 = pd.DataFrame({'Class': class_names,\n",
    "                            'True Distribution':pd.Series(y_test).value_counts(normalize=True).sort_index(),\n",
    "                           'Prediction Distribution':pd.Series(pred_val).value_counts(normalize=True).sort_index()}\n",
    "                          )\n",
    "        print(df2)\n",
    "        plot_confusion_matrix(y_test,pred_val,class_names)\n",
    "    \n",
    "    if plot_fea_imp:\n",
    "        # plot_feature_importances(_model.feature_importances_,trn_df.columns.values)\n",
    "        _ = plot_permutation_importances(_model,X_trn,y_trn)\n",
    "    \n",
    "    return _model,prob_trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/anhquan0412/that-ml-library/blob/main/that_ml_library/ml_helpers.py#L63){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### run_sklearn_classification_model\n",
       "\n",
       ">      run_sklearn_classification_model (model_name:str, model_params:dict,\n",
       ">                                        X_trn:pandas.core.frame.DataFrame|numpy\n",
       ">                                        .ndarray, y_trn:pandas.core.series.Seri\n",
       ">                                        es|numpy.ndarray, y_classes:list,\n",
       ">                                        val_ratio=0.2, seed=42,\n",
       ">                                        plot_fea_imp=True)\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| model_name | str |  | sklearn's Machine Learning model to try. Currently support DecisionTree,AdaBoost,RandomForest |\n",
       "| model_params | dict |  | A dictionary containing model's hyperparameters |\n",
       "| X_trn | pd.DataFrame \\| np.ndarray |  | Training features |\n",
       "| y_trn | pd.Series \\| np.ndarray |  | Training label |\n",
       "| y_classes | list |  | Display names matching the labels (same order). |\n",
       "| val_ratio | float | 0.2 | Validation set ratio for train_test_split |\n",
       "| seed | int | 42 | Random seed |\n",
       "| plot_fea_imp | bool | True | To plot feature importances (permutation technique) |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/anhquan0412/that-ml-library/blob/main/that_ml_library/ml_helpers.py#L63){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### run_sklearn_classification_model\n",
       "\n",
       ">      run_sklearn_classification_model (model_name:str, model_params:dict,\n",
       ">                                        X_trn:pandas.core.frame.DataFrame|numpy\n",
       ">                                        .ndarray, y_trn:pandas.core.series.Seri\n",
       ">                                        es|numpy.ndarray, y_classes:list,\n",
       ">                                        val_ratio=0.2, seed=42,\n",
       ">                                        plot_fea_imp=True)\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| model_name | str |  | sklearn's Machine Learning model to try. Currently support DecisionTree,AdaBoost,RandomForest |\n",
       "| model_params | dict |  | A dictionary containing model's hyperparameters |\n",
       "| X_trn | pd.DataFrame \\| np.ndarray |  | Training features |\n",
       "| y_trn | pd.Series \\| np.ndarray |  | Training label |\n",
       "| y_classes | list |  | Display names matching the labels (same order). |\n",
       "| val_ratio | float | 0.2 | Validation set ratio for train_test_split |\n",
       "| seed | int | 42 | Random seed |\n",
       "| plot_fea_imp | bool | True | To plot feature importances (permutation technique) |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(run_sklearn_classification_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def tune_sklearn_classification_model(model_name:str, # sklearn's Machine Learning model to try. Currently support DecisionTree,AdaBoost,RandomForest,\n",
    "                                      param_grid:dict, # Dictionary with parameters names (str) as keys and lists of parameter settings to try as values\n",
    "                                       X_trn:pd.DataFrame|np.ndarray, # Training features\n",
    "                                      y_trn:pd.Series|np.ndarray, # Training label\n",
    "                                      custom_cv=5, # sklearn's cross-validation splitting strategy\n",
    "                                      random_cv_iter=None, # Number of parameter settings that are sampled. Use this if you want to do RandomizedSearchCV\n",
    "                                      scoring='f1_macro', # Metric\n",
    "                                      seed=42, # Random seed\n",
    "                                      rank_show=10 # Number of ranks to show (descending order)\n",
    "                                     ):\n",
    "    \"Perform either Sklearn's Grid Search or Randomized Search (based on random_cv_iter) of the model using param_grid\"\n",
    "    if model_name=='DT':\n",
    "        _model = DecisionTreeClassifier(random_state=seed)\n",
    "    elif model_name=='AdaBoost':\n",
    "        dt = DecisionTreeClassifier(random_state=seed)\n",
    "        _model = AdaBoostClassifier(base_estimator= dt,random_state=seed,algorithm='SAMME')\n",
    "    elif model_name=='RF':\n",
    "        _model = RandomForestClassifier(random_state=seed)\n",
    "    else:\n",
    "        print('Unsupported model')\n",
    "        return\n",
    "    \n",
    "    search_cv,default_cv = do_param_search(X_trn,y_trn,_model,param_grid,cv=custom_cv,scoring=scoring,random_cv_iter = random_cv_iter,seed=seed)\n",
    "    # Default to show results for the first metric\n",
    "    show_both_cv(search_cv,default_cv,scoring[0],rank_show)\n",
    "    return search_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/anhquan0412/that-ml-library/blob/main/that_ml_library/ml_helpers.py#L123){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### tune_sklearn_classification_model\n",
       "\n",
       ">      tune_sklearn_classification_model (model_name:str, param_grid:dict,\n",
       ">                                         X_trn:pandas.core.frame.DataFrame|nump\n",
       ">                                         y.ndarray, y_trn:pandas.core.series.Se\n",
       ">                                         ries|numpy.ndarray, custom_cv=5,\n",
       ">                                         random_cv_iter=None,\n",
       ">                                         scoring='f1_macro', seed=42,\n",
       ">                                         rank_show=10)\n",
       "\n",
       "Perform either Sklearn's Grid Search or Randomized Search (based on random_cv_iter) of the model using param_grid\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| model_name | str |  | sklearn's Machine Learning model to try. Currently support DecisionTree,AdaBoost,RandomForest, |\n",
       "| param_grid | dict |  | Dictionary with parameters names (str) as keys and lists of parameter settings to try as values |\n",
       "| X_trn | pd.DataFrame \\| np.ndarray |  | Training features |\n",
       "| y_trn | pd.Series \\| np.ndarray |  | Training label |\n",
       "| custom_cv | int | 5 | sklearn's cross-validation splitting strategy |\n",
       "| random_cv_iter | NoneType | None | Number of parameter settings that are sampled. Use this if you want to do RandomizedSearchCV |\n",
       "| scoring | str | f1_macro | Metric |\n",
       "| seed | int | 42 | Random seed |\n",
       "| rank_show | int | 10 | Number of ranks to show (descending order) |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/anhquan0412/that-ml-library/blob/main/that_ml_library/ml_helpers.py#L123){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### tune_sklearn_classification_model\n",
       "\n",
       ">      tune_sklearn_classification_model (model_name:str, param_grid:dict,\n",
       ">                                         X_trn:pandas.core.frame.DataFrame|nump\n",
       ">                                         y.ndarray, y_trn:pandas.core.series.Se\n",
       ">                                         ries|numpy.ndarray, custom_cv=5,\n",
       ">                                         random_cv_iter=None,\n",
       ">                                         scoring='f1_macro', seed=42,\n",
       ">                                         rank_show=10)\n",
       "\n",
       "Perform either Sklearn's Grid Search or Randomized Search (based on random_cv_iter) of the model using param_grid\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| model_name | str |  | sklearn's Machine Learning model to try. Currently support DecisionTree,AdaBoost,RandomForest, |\n",
       "| param_grid | dict |  | Dictionary with parameters names (str) as keys and lists of parameter settings to try as values |\n",
       "| X_trn | pd.DataFrame \\| np.ndarray |  | Training features |\n",
       "| y_trn | pd.Series \\| np.ndarray |  | Training label |\n",
       "| custom_cv | int | 5 | sklearn's cross-validation splitting strategy |\n",
       "| random_cv_iter | NoneType | None | Number of parameter settings that are sampled. Use this if you want to do RandomizedSearchCV |\n",
       "| scoring | str | f1_macro | Metric |\n",
       "| seed | int | 42 | Random seed |\n",
       "| rank_show | int | 10 | Number of ranks to show (descending order) |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(tune_sklearn_classification_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def do_param_search(\n",
    "    X_train,y_train,\n",
    "    estimator,\n",
    "    param_grid,\n",
    "    random_cv_iter=None,\n",
    "    include_default=True,\n",
    "    cv=None,\n",
    "    scoring=None,\n",
    "    seed=42\n",
    "    \n",
    "):\n",
    "    scoring = val2list(scoring)\n",
    "    search_cv,default_cv=None,None\n",
    "    if random_cv_iter:\n",
    "        search_cv = RandomizedSearchCV(estimator=estimator,\n",
    "                                      n_iter=random_cv_iter,\n",
    "                                      param_distributions=param_grid,\n",
    "                                      scoring=scoring,\n",
    "                                      n_jobs=-1,\n",
    "                                      cv=cv,\n",
    "                                        return_train_score=True,\n",
    "                                      verbose=1,refit=False,random_state=seed)\n",
    "        search_cv.fit(X_train,y_train)\n",
    "    else:\n",
    "        search_cv = GridSearchCV(estimator,param_grid,scoring=scoring,n_jobs=-1,cv=cv,verbose=1,\n",
    "                                 return_train_score=True,refit=False)\n",
    "        search_cv.fit(X_train,y_train)\n",
    "    if include_default:\n",
    "        default_cv = cross_validate(estimator,X_train,y_train,scoring=scoring,cv=cv,n_jobs=-1,verbose=1,\n",
    "                                   return_train_score=True)\n",
    "    return search_cv.cv_results_,default_cv\n",
    "        \n",
    "\n",
    "def summarize_cv_results(search_cv,scoring,top_n=10):\n",
    "    search_cv = pd.DataFrame(search_cv)\n",
    "    search_cv = search_cv.sort_values(f'rank_test_{scoring}')\n",
    "    for rec in search_cv[['params',f'mean_train_{scoring}',f'std_train_{scoring}',f'mean_test_{scoring}',f'std_test_{scoring}',f'rank_test_{scoring}']].values[:top_n]:\n",
    "        print('-'*10)\n",
    "        print(f'Rank {rec[-1]}')\n",
    "        print(f'Params: {rec[0]}')\n",
    "        print(f'Mean train score: {rec[1]:.3f} +- {rec[2]:.3f}')\n",
    "        print(f'Mean test score: {rec[3]:.3f} +- {rec[4]:.3f}')\n",
    "\n",
    "def summarize_default_cv(default_cv,s):\n",
    "    print('-'*10)\n",
    "    print(\"Default Params\")\n",
    "    print(f\"Mean train score: {round(default_cv[f'train_{s}'].mean(),3)} +- {round(default_cv[f'train_{s}'].std(),3)}\")\n",
    "    print(f\"Mean test score: {round(default_cv[f'test_{s}'].mean(),3)} +- {round(default_cv[f'test_{s}'].std(),3)}\")\n",
    "\n",
    "def show_both_cv(search_cv,default_cv,scoring,top_n=10):\n",
    "    summarize_cv_results(search_cv,scoring,top_n)\n",
    "    summarize_default_cv(default_cv,scoring)\n",
    "\n",
    "    \n",
    "def get_adaboost_info(dt_params,ada_params,X,y,seed=42):\n",
    "    dt = DecisionTreeClassifier(random_state=seed,**dt_params)\n",
    "    abc = AdaBoostClassifier(base_estimator=dt,random_state=seed,**ada_params)\n",
    "    abc.fit(X,y)\n",
    "    for i,t in enumerate(abc.estimators_):\n",
    "        print(f'{t}\\n\\tTree depth: {t.tree_.max_depth}, Weight: {abc.estimator_weights_[i]}, Error: {abc.estimator_errors_[i]}')\n",
    "    return abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
