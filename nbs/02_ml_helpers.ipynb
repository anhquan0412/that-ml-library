{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ml_helpers\n",
    "\n",
    "\n",
    "> This module contains several Python functions for running a quick ML prototype on your processed dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp ml_helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "from that_ml_library.utils import *\n",
    "from that_ml_library.chart_plotting import plot_permutation_importances,plot_confusion_matrix,plot_residuals,plot_feature_importances\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_validate, train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor\n",
    "from sklearn.metrics import f1_score,accuracy_score,classification_report,log_loss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def run_logistic_regression(X_trn:pd.DataFrame, # Training dataframe\n",
    "                            y_trn:pd.Series|np.ndarray, # Training label\n",
    "                            multi_class='multinomial', # sklearn's log reg multiclass option\n",
    "                            solver='newton-cg', # sklearn's log reg solver option\n",
    "                            penalty=None, # sklearn's log reg penalty option\n",
    "                            max_iter=10000 # sklearn's log reg max iteration option\n",
    "                           ):\n",
    "    \"Perform Sklearn logistic regression, then print coefficients and classification report\"\n",
    "    model = LogisticRegression(random_state=0, multi_class=multi_class, \n",
    "                               penalty=penalty, solver=solver,max_iter=max_iter).fit(X_trn, y_trn)\n",
    "    preds = model.predict(X_trn)\n",
    "    prob_preds = model.predict_proba(X_trn)\n",
    "    print('-'*100)\n",
    "    print('Intercept: \\n', model.intercept_)\n",
    "    print('Coefficients: \\n', model.coef_)\n",
    "    print('Coefficients exp :\\n',np.exp(model.coef_))\n",
    "\n",
    "    print('-'*100)\n",
    "    print('Log loss: ',log_loss(y_trn,prob_preds))\n",
    "    print('-'*100)\n",
    "    print(classification_report(y_trn,preds))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/anhquan0412/that-ml-library/blob/main/that_ml_library/ml_helpers.py#L24){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### run_logistic_regression\n",
       "\n",
       ">      run_logistic_regression (X_trn:pandas.core.frame.DataFrame,\n",
       ">                               y_trn:pandas.core.series.Series|numpy.ndarray,\n",
       ">                               multi_class='multinomial', solver='newton-cg',\n",
       ">                               penalty=None, max_iter=10000)\n",
       "\n",
       "Perform Sklearn logistic regression, then print coefficients and classification report\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| X_trn | pd.DataFrame |  | Training dataframe |\n",
       "| y_trn | pd.Series \\| np.ndarray |  | Training label |\n",
       "| multi_class | str | multinomial | sklearn's log reg multiclass option |\n",
       "| solver | str | newton-cg | sklearn's log reg solver option |\n",
       "| penalty | NoneType | None | sklearn's log reg penalty option |\n",
       "| max_iter | int | 10000 | sklearn's log reg max iteration option |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/anhquan0412/that-ml-library/blob/main/that_ml_library/ml_helpers.py#L24){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### run_logistic_regression\n",
       "\n",
       ">      run_logistic_regression (X_trn:pandas.core.frame.DataFrame,\n",
       ">                               y_trn:pandas.core.series.Series|numpy.ndarray,\n",
       ">                               multi_class='multinomial', solver='newton-cg',\n",
       ">                               penalty=None, max_iter=10000)\n",
       "\n",
       "Perform Sklearn logistic regression, then print coefficients and classification report\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| X_trn | pd.DataFrame |  | Training dataframe |\n",
       "| y_trn | pd.Series \\| np.ndarray |  | Training label |\n",
       "| multi_class | str | multinomial | sklearn's log reg multiclass option |\n",
       "| solver | str | newton-cg | sklearn's log reg solver option |\n",
       "| penalty | NoneType | None | sklearn's log reg penalty option |\n",
       "| max_iter | int | 10000 | sklearn's log reg max iteration option |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(run_logistic_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def run_multinomial_statmodel(X_trn:pd.DataFrame, # Training dataframe\n",
    "                              y_trn:pd.Series|np.ndarray, # Training label\n",
    "                              add_constant=True # To add a constant column to X_trn\n",
    "                             ):\n",
    "    \"Perform multinominal logit from statsmodel, then print results and classification report\"\n",
    "    if add_constant:\n",
    "        X_trn = sm.add_constant(X_trn)\n",
    "    logit_model=sm.MNLogit(y_trn,X_trn)\n",
    "    result=logit_model.fit()\n",
    "    stats1=result.summary()\n",
    "    print(stats1)\n",
    "    prob_preds = logit_model.predict(params = result.params.values)\n",
    "    print('-'*100)\n",
    "    print('Log loss: ',log_loss(y_trn,prob_preds))\n",
    "    print('-'*100)\n",
    "    print(classification_report(y_trn,np.argmax(prob_preds,axis=1)))\n",
    "    return logit_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/anhquan0412/that-ml-library/blob/main/that_ml_library/ml_helpers.py#L48){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### run_multinomial_statmodel\n",
       "\n",
       ">      run_multinomial_statmodel (X_trn:pandas.core.frame.DataFrame,\n",
       ">                                 y_trn:pandas.core.series.Series|numpy.ndarray,\n",
       ">                                 add_constant=True)\n",
       "\n",
       "Perform multinominal logit from statsmodel, then print results and classification report\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| X_trn | pd.DataFrame |  | Training dataframe |\n",
       "| y_trn | pd.Series \\| np.ndarray |  | Training label |\n",
       "| add_constant | bool | True | To add a constant column to X_trn |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/anhquan0412/that-ml-library/blob/main/that_ml_library/ml_helpers.py#L48){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### run_multinomial_statmodel\n",
       "\n",
       ">      run_multinomial_statmodel (X_trn:pandas.core.frame.DataFrame,\n",
       ">                                 y_trn:pandas.core.series.Series|numpy.ndarray,\n",
       ">                                 add_constant=True)\n",
       "\n",
       "Perform multinominal logit from statsmodel, then print results and classification report\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| X_trn | pd.DataFrame |  | Training dataframe |\n",
       "| y_trn | pd.Series \\| np.ndarray |  | Training label |\n",
       "| add_constant | bool | True | To add a constant column to X_trn |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(run_multinomial_statmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def run_sklearn_model(model_name:str, # sklearn's Machine Learning model to try. Currently support DecisionTree,AdaBoost,RandomForest\n",
    "                      model_params:dict, # A dictionary containing model's hyperparameters\n",
    "                      X_trn:pd.DataFrame, # Training dataframe\n",
    "                      y_trn:pd.Series|np.ndarray, # Training label\n",
    "                      is_regression=False, # To use regression model or classification model\n",
    "                      class_names:list=None, # List of names associated with the labels (same order); e.g. ['no','yes']. For classification only\n",
    "                      test_split=None, # Test set split. If float: random split. If list of list: indices of train and test set. If None: skip splitting\n",
    "                      metric_funcs={}, # Dictionary of metric functions: {metric_name:metric_func}\n",
    "                      seed=42, # Random seed\n",
    "                      plot_fea_imp=True # To whether plot sklearn's feature importances. Set to False to skip the plot\n",
    "                    ):\n",
    "    np.random.seed(seed)\n",
    "    if isinstance(test_split,float):\n",
    "        X_trn,X_test,y_trn,y_test = train_test_split(X_trn,y_trn,test_size=test_split,random_state=seed)\n",
    "    if isinstance(test_split,list) and len(test_split)==2 and isinstance(test_split[0],list) and isinstance(test_split[1],list):\n",
    "        X_test = X_trn.iloc[test_split[1]].copy()\n",
    "        y_test = y_trn[test_split[1]]\n",
    "        y_trn = y_trn[test_split[0]]\n",
    "        X_trn = X_trn.iloc[test_split[0]]\n",
    "\n",
    "    if model_name=='DecisionTree':\n",
    "        if is_regression:\n",
    "            _model = DecisionTreeRegressor(random_state=seed,**model_params)\n",
    "        else:\n",
    "            _model = DecisionTreeClassifier(random_state=seed,**model_params)\n",
    "    elif model_name=='AdaBoost':\n",
    "        dt_params={k.split('__')[1]:v for k,v in model_params.items() if 'base_estimator' in k}\n",
    "        abc_params={k:v for k,v in model_params.items() if 'base_estimator' not in k}        \n",
    "        print(f'Decision Tree params: {dt_params}')\n",
    "        print(f'AdaBoost params: {abc_params}')\n",
    "        if is_regression:\n",
    "            dt = DecisionTreeRegressor(random_state=seed,**dt_params)\n",
    "            _model = AdaBoostRegressor(base_estimator=dt,random_state=seed,algorithm='SAMME',**abc_params)\n",
    "        else:\n",
    "            dt = DecisionTreeClassifier(random_state=seed,**dt_params)\n",
    "            _model = AdaBoostClassifier(base_estimator=dt,random_state=seed,**abc_params)\n",
    "    elif model_name=='RandomForest':\n",
    "        if is_regression:\n",
    "            _model = RandomForestRegressor(random_state=seed,**model_params)\n",
    "        else:\n",
    "            _model = RandomForestClassifier(random_state=seed,**model_params)\n",
    "    else:\n",
    "        print('Unsupported model')\n",
    "        return\n",
    "\n",
    "    _model = _model.fit(X_trn,y_trn)\n",
    "    pred_trn = _model.predict(X_trn)\n",
    "    \n",
    "    # For regression:\n",
    "    if is_regression:\n",
    "        print('-'*30 + ' Train set ' + '-'*30)\n",
    "        for k,v in metric_funcs.items():\n",
    "            print(f'{k}: {v(y_trn,pred_trn)}')\n",
    "        \n",
    "        if test_split is not None:\n",
    "            print('-'*30 + ' Test set ' + '-'*30)\n",
    "            pred_test = _model.predict(X_test)\n",
    "            for k,v in metric_funcs.items():\n",
    "                print(f'{k}: {v(y_test,pred_test)}')\n",
    "            \n",
    "            # plot residual plot\n",
    "            plot_residuals(_model,X_trn,y_trn,X_test,y_test,\n",
    "                           is_fit=True,\n",
    "                           qqplot=True)\n",
    "        else:\n",
    "            plot_residuals(_model,X_trn,y_trn,\n",
    "                           is_fit=True,\n",
    "                           qqplot=True)\n",
    "\n",
    "    # For classification\n",
    "    else:\n",
    "        prob_trn = _model.predict_proba(X_trn)\n",
    "        print('-'*30 + ' Train set ' + '-'*30)\n",
    "        print(f'Log loss: {log_loss(y_trn,prob_trn)}')\n",
    "#         for k,v in metric_funcs.items():\n",
    "#             print(f'{k}: {v(y_trn,prob_trn)}')\n",
    "        print(classification_report(y_trn, pred_trn, target_names=class_names))\n",
    "        if test_split is not None:\n",
    "            print('-'*30 + ' Test set ' + '-'*30)\n",
    "            pred_test = _model.predict(X_test)\n",
    "            prob_test = _model.predict_proba(X_test)\n",
    "            print(f'Log loss: {log_loss(y_test,prob_test)}')\n",
    "            print(classification_report(y_test, pred_test, target_names=class_names))\n",
    "            print('-'*100)\n",
    "            df2 = pd.DataFrame({'Class': class_names,\n",
    "                                'True Distribution':pd.Series(y_test).value_counts(normalize=True).sort_index(),\n",
    "                               'Prediction Distribution':pd.Series(pred_test).value_counts(normalize=True).sort_index()}\n",
    "                              )\n",
    "            print(df2)\n",
    "            plot_confusion_matrix(y_test,pred_test,class_names)\n",
    "\n",
    "\n",
    "#     _ = plot_permutation_importances(_model,X_trn,y_trn,scoring=['neg_root_mean_squared_error'])\n",
    "    if plot_fea_imp:\n",
    "        plot_feature_importances(_model.feature_importances_,X_trn.columns.values)\n",
    "    \n",
    "    return _model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/anhquan0412/that-ml-library/blob/main/that_ml_library/ml_helpers.py#L67){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### run_sklearn_model\n",
       "\n",
       ">      run_sklearn_model (model_name:str, model_params:dict,\n",
       ">                         X_trn:pandas.core.frame.DataFrame,\n",
       ">                         y_trn:pandas.core.series.Series|numpy.ndarray,\n",
       ">                         is_regression=False, class_names:list=None,\n",
       ">                         test_split=None, metric_funcs={}, seed=42,\n",
       ">                         plot_fea_imp=True)\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| model_name | str |  | sklearn's Machine Learning model to try. Currently support DecisionTree,AdaBoost,RandomForest |\n",
       "| model_params | dict |  | A dictionary containing model's hyperparameters |\n",
       "| X_trn | pd.DataFrame |  | Training dataframe |\n",
       "| y_trn | pd.Series \\| np.ndarray |  | Training label |\n",
       "| is_regression | bool | False | To use regression model or classification model |\n",
       "| class_names | list | None | List of names associated with the labels (same order); e.g. ['no','yes']. For classification only |\n",
       "| test_split | NoneType | None | Test set split. If float: random split. If list of list: indices of train and test set. If None: skip splitting |\n",
       "| metric_funcs | dict | {} | Dictionary of metric functions: {metric_name:metric_func} |\n",
       "| seed | int | 42 | Random seed |\n",
       "| plot_fea_imp | bool | True | To whether plot sklearn's feature importances. Set to False to skip the plot |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/anhquan0412/that-ml-library/blob/main/that_ml_library/ml_helpers.py#L67){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### run_sklearn_model\n",
       "\n",
       ">      run_sklearn_model (model_name:str, model_params:dict,\n",
       ">                         X_trn:pandas.core.frame.DataFrame,\n",
       ">                         y_trn:pandas.core.series.Series|numpy.ndarray,\n",
       ">                         is_regression=False, class_names:list=None,\n",
       ">                         test_split=None, metric_funcs={}, seed=42,\n",
       ">                         plot_fea_imp=True)\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| model_name | str |  | sklearn's Machine Learning model to try. Currently support DecisionTree,AdaBoost,RandomForest |\n",
       "| model_params | dict |  | A dictionary containing model's hyperparameters |\n",
       "| X_trn | pd.DataFrame |  | Training dataframe |\n",
       "| y_trn | pd.Series \\| np.ndarray |  | Training label |\n",
       "| is_regression | bool | False | To use regression model or classification model |\n",
       "| class_names | list | None | List of names associated with the labels (same order); e.g. ['no','yes']. For classification only |\n",
       "| test_split | NoneType | None | Test set split. If float: random split. If list of list: indices of train and test set. If None: skip splitting |\n",
       "| metric_funcs | dict | {} | Dictionary of metric functions: {metric_name:metric_func} |\n",
       "| seed | int | 42 | Random seed |\n",
       "| plot_fea_imp | bool | True | To whether plot sklearn's feature importances. Set to False to skip the plot |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(run_sklearn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def tune_sklearn_model(model_name:str, # sklearn's Machine Learning model to try. Currently support DecisionTree,AdaBoost,RandomForest,\n",
    "                      param_grid:dict, # Dictionary with parameters names (str) as keys and lists of parameter settings to try as values\n",
    "                      X_trn:pd.DataFrame, # Training dataframe\n",
    "                      y_trn:pd.Series|np.ndarray, # Training label\n",
    "                      is_regression=False, # Is it a regression problem, or classification?\n",
    "                      custom_cv=5, # sklearn's cross-validation splitting strategy\n",
    "                      random_cv_iter=None, # Number of parameter settings that are sampled. Use this if you want to do RandomizedSearchCV\n",
    "                      scoring=None, # Metric\n",
    "                      seed=42, # Random seed\n",
    "                      rank_show=10, # Number of ranks to show (descending order)\n",
    "                      show_split_scores=True, # To show both train and test split scores\n",
    "                     ):\n",
    "    \"Perform either Sklearn's Grid Search or Randomized Search (based on random_cv_iter) of the model using param_grid\"\n",
    "    if is_regression:\n",
    "        if model_name=='DecisionTree':\n",
    "            _model = DecisionTreeRegressor(random_state=seed)\n",
    "        elif model_name=='AdaBoost':\n",
    "            dt = DecisionTreeRegressor(random_state=seed)\n",
    "            _model = AdaBoostRegressor(base_estimator= dt,random_state=seed)\n",
    "        elif model_name=='RandomForest':\n",
    "            _model = RandomForestRegressor(random_state=seed)\n",
    "        else:\n",
    "            print('Unsupported model')\n",
    "            return\n",
    "    else:\n",
    "        if model_name=='DecisionTree':\n",
    "            _model = DecisionTreeClassifier(random_state=seed)\n",
    "        elif model_name=='AdaBoost':\n",
    "            dt = DecisionTreeClassifier(random_state=seed)\n",
    "            _model = AdaBoostClassifier(base_estimator= dt,random_state=seed,algorithm='SAMME')\n",
    "        elif model_name=='RandomForest':\n",
    "            _model = RandomForestClassifier(random_state=seed)\n",
    "        else:\n",
    "            print('Unsupported model')\n",
    "            return\n",
    "    \n",
    "    scoring = val2list(scoring)\n",
    "    search_cv,default_cv = do_param_search(X_trn,y_trn,_model,param_grid,cv=custom_cv,scoring=scoring,random_cv_iter = random_cv_iter,seed=seed)\n",
    "    # Default to show results for the first metric\n",
    "    show_both_cv(search_cv,default_cv,scoring[0],rank_show,show_split_scores)\n",
    "    return search_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/anhquan0412/that-ml-library/blob/main/that_ml_library/ml_helpers.py#L166){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### tune_sklearn_model\n",
       "\n",
       ">      tune_sklearn_model (model_name:str, param_grid:dict,\n",
       ">                          X_trn:pandas.core.frame.DataFrame,\n",
       ">                          y_trn:pandas.core.series.Series|numpy.ndarray,\n",
       ">                          is_regression=False, custom_cv=5,\n",
       ">                          random_cv_iter=None, scoring=None, seed=42,\n",
       ">                          rank_show=10, show_split_scores=True)\n",
       "\n",
       "Perform either Sklearn's Grid Search or Randomized Search (based on random_cv_iter) of the model using param_grid\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| model_name | str |  | sklearn's Machine Learning model to try. Currently support DecisionTree,AdaBoost,RandomForest, |\n",
       "| param_grid | dict |  | Dictionary with parameters names (str) as keys and lists of parameter settings to try as values |\n",
       "| X_trn | pd.DataFrame |  | Training dataframe |\n",
       "| y_trn | pd.Series \\| np.ndarray |  | Training label |\n",
       "| is_regression | bool | False | Is it a regression problem, or classification? |\n",
       "| custom_cv | int | 5 | sklearn's cross-validation splitting strategy |\n",
       "| random_cv_iter | NoneType | None | Number of parameter settings that are sampled. Use this if you want to do RandomizedSearchCV |\n",
       "| scoring | NoneType | None | Metric |\n",
       "| seed | int | 42 | Random seed |\n",
       "| rank_show | int | 10 | Number of ranks to show (descending order) |\n",
       "| show_split_scores | bool | True | To show both train and test split scores |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/anhquan0412/that-ml-library/blob/main/that_ml_library/ml_helpers.py#L166){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### tune_sklearn_model\n",
       "\n",
       ">      tune_sklearn_model (model_name:str, param_grid:dict,\n",
       ">                          X_trn:pandas.core.frame.DataFrame,\n",
       ">                          y_trn:pandas.core.series.Series|numpy.ndarray,\n",
       ">                          is_regression=False, custom_cv=5,\n",
       ">                          random_cv_iter=None, scoring=None, seed=42,\n",
       ">                          rank_show=10, show_split_scores=True)\n",
       "\n",
       "Perform either Sklearn's Grid Search or Randomized Search (based on random_cv_iter) of the model using param_grid\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| model_name | str |  | sklearn's Machine Learning model to try. Currently support DecisionTree,AdaBoost,RandomForest, |\n",
       "| param_grid | dict |  | Dictionary with parameters names (str) as keys and lists of parameter settings to try as values |\n",
       "| X_trn | pd.DataFrame |  | Training dataframe |\n",
       "| y_trn | pd.Series \\| np.ndarray |  | Training label |\n",
       "| is_regression | bool | False | Is it a regression problem, or classification? |\n",
       "| custom_cv | int | 5 | sklearn's cross-validation splitting strategy |\n",
       "| random_cv_iter | NoneType | None | Number of parameter settings that are sampled. Use this if you want to do RandomizedSearchCV |\n",
       "| scoring | NoneType | None | Metric |\n",
       "| seed | int | 42 | Random seed |\n",
       "| rank_show | int | 10 | Number of ranks to show (descending order) |\n",
       "| show_split_scores | bool | True | To show both train and test split scores |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(tune_sklearn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def do_param_search(\n",
    "    X_train,y_train,\n",
    "    estimator,\n",
    "    param_grid,\n",
    "    random_cv_iter=None,\n",
    "    include_default=True,\n",
    "    cv=None,\n",
    "    scoring=None,\n",
    "    seed=42\n",
    "    \n",
    "):\n",
    "    scoring = val2list(scoring)\n",
    "    search_cv,default_cv=None,None\n",
    "    if random_cv_iter:\n",
    "        search_cv = RandomizedSearchCV(estimator=estimator,\n",
    "                                      n_iter=random_cv_iter,\n",
    "                                      param_distributions=param_grid,\n",
    "                                      scoring=scoring,\n",
    "                                      n_jobs=-1,\n",
    "                                      cv=cv,\n",
    "                                        return_train_score=True,\n",
    "                                      verbose=1,refit=False,random_state=seed)\n",
    "        search_cv.fit(X_train,y_train)\n",
    "    else:\n",
    "        search_cv = GridSearchCV(estimator,param_grid,scoring=scoring,n_jobs=-1,cv=cv,verbose=1,\n",
    "                                 return_train_score=True,refit=False)\n",
    "        search_cv.fit(X_train,y_train)\n",
    "    if include_default:\n",
    "        default_cv = cross_validate(estimator,X_train,y_train,scoring=scoring,cv=cv,n_jobs=-1,verbose=1,\n",
    "                                   return_train_score=True)\n",
    "    return search_cv.cv_results_,default_cv\n",
    "        \n",
    "\n",
    "def summarize_cv_results(search_cv,scoring,top_n=10,show_split_scores=False):\n",
    "    num_split = len([c for c in search_cv.keys() if re.search(r'split\\d_test', c)])\n",
    "    search_cv = pd.DataFrame(search_cv)\n",
    "    search_cv = search_cv.sort_values(f'rank_test_{scoring}')\n",
    "    for rec in search_cv[['params',f'mean_train_{scoring}',f'std_train_{scoring}',\n",
    "                          f'mean_test_{scoring}',f'std_test_{scoring}',f'rank_test_{scoring}']+\n",
    "                         [f'split{i}_train_{scoring}' for i in range(num_split)] +\n",
    "                         [f'split{i}_test_{scoring}' for i in range(num_split)]\n",
    "                        ].values[:top_n]:\n",
    "        print('-'*10)\n",
    "        print(f'Rank {rec[5]}')\n",
    "        print(f'Params: {rec[0]}')\n",
    "        if show_split_scores:\n",
    "            print(f'Train scores: {[round(i,2) for i in rec[6:6+num_split]]}')\n",
    "        print(f'Mean train score: {rec[1]:.3f} +- {rec[2]:.3f}')\n",
    "        if show_split_scores:\n",
    "            print(f'Test scores:  {[round(i,2) for i in rec[-num_split:]]}')\n",
    "        print(f'Mean test score: {rec[3]:.3f} +- {rec[4]:.3f}')\n",
    "\n",
    "def summarize_default_cv(default_cv,s):\n",
    "    print('-'*10)\n",
    "    print(\"Default Params\")\n",
    "    print(f\"Mean train score: {round(default_cv[f'train_{s}'].mean(),3)} +- {round(default_cv[f'train_{s}'].std(),3)}\")\n",
    "    print(f\"Mean test score: {round(default_cv[f'test_{s}'].mean(),3)} +- {round(default_cv[f'test_{s}'].std(),3)}\")\n",
    "\n",
    "def show_both_cv(search_cv,default_cv,scoring,top_n=10,show_split_scores=False):\n",
    "    summarize_cv_results(search_cv,scoring,top_n,show_split_scores)\n",
    "    summarize_default_cv(default_cv,scoring)\n",
    "\n",
    "    \n",
    "def get_adaboost_info(dt_params,ada_params,X,y,seed=42):\n",
    "    dt = DecisionTreeClassifier(random_state=seed,**dt_params)\n",
    "    abc = AdaBoostClassifier(base_estimator=dt,random_state=seed,**ada_params)\n",
    "    abc.fit(X,y)\n",
    "    for i,t in enumerate(abc.estimators_):\n",
    "        print(f'{t}\\n\\tTree depth: {t.tree_.max_depth}, Weight: {abc.estimator_weights_[i]}, Error: {abc.estimator_errors_[i]}')\n",
    "    return abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
